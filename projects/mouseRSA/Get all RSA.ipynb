{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import everthing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/dynamic-brain-workshop/brain_observatory_cache/brain_observatory_manifest.json\n"
     ]
    }
   ],
   "source": [
    "#make sure your drive path is correct! \n",
    "# macOS/OS X\n",
    "# drive_path = '/Volumes/Brain2017/data/dynamic-brain-workshop/brain_observatory_cache/'\n",
    "\n",
    "# Linux (will vary; the following is possibly what Ubuntu will do)\n",
    "# drive_path = '/media/Brain2017/data/dynamic-brain-workshop/brain_observatory_cache'\n",
    "\n",
    "# AWS\n",
    "drive_path = '/data/dynamic-brain-workshop/brain_observatory_cache/'\n",
    "\n",
    "# We need to import these modules to get started\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import h5py\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from allensdk.core.brain_observatory_cache import BrainObservatoryCache\n",
    "\n",
    "manifest_file = os.path.join(drive_path,'brain_observatory_manifest.json')\n",
    "print manifest_file\n",
    "\n",
    "boc = BrainObservatoryCache(manifest_file=manifest_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from allensdk.brain_observatory.natural_scenes import NaturalScenes\n",
    "from allensdk.brain_observatory.static_gratings import StaticGratings\n",
    "from allensdk.brain_observatory.natural_movie import NaturalMovie\n",
    "from scipy.stats import binned_statistic\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import SpectralEmbedding, MDS\n",
    "from sklearn.covariance import EmpiricalCovariance\n",
    "from scipy.spatial.distance import squareform, pdist\n",
    "\n",
    "scriptpath = '/home/arib/SWDB_2017/swdb_2017_tools'\n",
    "sys.path.append(scriptpath)\n",
    "\n",
    "from swdb2017.brain_observatory.RSA_with_options import *\n",
    "\n",
    "from swdb2017.brain_observatory.get_rsm import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get all experiement ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all targeted structures: [u'VISal', u'VISam', u'VISl', u'VISp', u'VISpm', u'VISrl']\n",
      "all imaging depths: [175, 265, 275, 300, 320, 325, 335, 350, 365, 375, 435]\n",
      "all cre lines: [u'Cux2-CreERT2', u'Emx1-IRES-Cre', u'Nr5a1-Cre', u'Rbp4-Cre_KL100', u'Rorb-IRES2-Cre', u'Scnn1a-Tg3-Cre']\n"
     ]
    }
   ],
   "source": [
    "# Download a list of all targeted areas\n",
    "targeted_structures = boc.get_all_targeted_structures()\n",
    "print 'all targeted structures: ' + str(targeted_structures)\n",
    "\n",
    "# Download a list of all imaging depths\n",
    "depths = boc.get_all_imaging_depths()\n",
    "print 'all imaging depths: ' + str(depths)\n",
    "\n",
    "# Download a list of all cre driver lines \n",
    "cre_lines = boc.get_all_cre_lines()\n",
    "print 'all cre lines: ' + str(cre_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cre_line</th>\n",
       "      <th>donor_name</th>\n",
       "      <th>failed</th>\n",
       "      <th>id</th>\n",
       "      <th>imaging_depth</th>\n",
       "      <th>reporter_line</th>\n",
       "      <th>specimen_name</th>\n",
       "      <th>tags</th>\n",
       "      <th>targeted_structure</th>\n",
       "      <th>rsa_mean_mean_mahala</th>\n",
       "      <th>rsa_random_mean_mahala</th>\n",
       "      <th>rsa_mean_mean_spectral_embedding</th>\n",
       "      <th>rsa_mean_mean_PCA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Cux2-CreERT2</td>\n",
       "      <td>283284</td>\n",
       "      <td>False</td>\n",
       "      <td>566759225</td>\n",
       "      <td>275</td>\n",
       "      <td>Ai93(TITL-GCaMP6f)</td>\n",
       "      <td>Cux2-CreERT2;Camk2a-tTA;Ai93-283284</td>\n",
       "      <td>[]</td>\n",
       "      <td>VISam</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Nr5a1-Cre</td>\n",
       "      <td>261969</td>\n",
       "      <td>False</td>\n",
       "      <td>546328009</td>\n",
       "      <td>350</td>\n",
       "      <td>Ai93(TITL-GCaMP6f)</td>\n",
       "      <td>Nr5a1-Cre;Camk2a-tTA;Ai93-261969</td>\n",
       "      <td>[]</td>\n",
       "      <td>VISal</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Scnn1a-Tg3-Cre</td>\n",
       "      <td>230570</td>\n",
       "      <td>False</td>\n",
       "      <td>511510911</td>\n",
       "      <td>350</td>\n",
       "      <td>Ai93(TITL-GCaMP6f)</td>\n",
       "      <td>Scnn1a-Tg3-Cre;Camk2a-tTA;Ai93-230570</td>\n",
       "      <td>[]</td>\n",
       "      <td>VISp</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Emx1-IRES-Cre</td>\n",
       "      <td>284669</td>\n",
       "      <td>False</td>\n",
       "      <td>569792815</td>\n",
       "      <td>375</td>\n",
       "      <td>Ai93(TITL-GCaMP6f)</td>\n",
       "      <td>Emx1-IRES-Cre;Camk2a-tTA;Ai93-284669</td>\n",
       "      <td>[]</td>\n",
       "      <td>VISam</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Rbp4-Cre_KL100</td>\n",
       "      <td>234584</td>\n",
       "      <td>False</td>\n",
       "      <td>511511015</td>\n",
       "      <td>375</td>\n",
       "      <td>Ai93(TITL-GCaMP6f)</td>\n",
       "      <td>Rbp4-Cre;Camk2a-tTA;Ai93-234584</td>\n",
       "      <td>[]</td>\n",
       "      <td>VISpm</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         cre_line donor_name failed         id  imaging_depth  \\\n",
       "0    Cux2-CreERT2     283284  False  566759225            275   \n",
       "1       Nr5a1-Cre     261969  False  546328009            350   \n",
       "2  Scnn1a-Tg3-Cre     230570  False  511510911            350   \n",
       "3   Emx1-IRES-Cre     284669  False  569792815            375   \n",
       "4  Rbp4-Cre_KL100     234584  False  511511015            375   \n",
       "\n",
       "        reporter_line                          specimen_name tags  \\\n",
       "0  Ai93(TITL-GCaMP6f)    Cux2-CreERT2;Camk2a-tTA;Ai93-283284   []   \n",
       "1  Ai93(TITL-GCaMP6f)       Nr5a1-Cre;Camk2a-tTA;Ai93-261969   []   \n",
       "2  Ai93(TITL-GCaMP6f)  Scnn1a-Tg3-Cre;Camk2a-tTA;Ai93-230570   []   \n",
       "3  Ai93(TITL-GCaMP6f)   Emx1-IRES-Cre;Camk2a-tTA;Ai93-284669   []   \n",
       "4  Ai93(TITL-GCaMP6f)        Rbp4-Cre;Camk2a-tTA;Ai93-234584   []   \n",
       "\n",
       "  targeted_structure rsa_mean_mean_mahala rsa_random_mean_mahala  \\\n",
       "0              VISam                    0                      0   \n",
       "1              VISal                    0                      0   \n",
       "2               VISp                    0                      0   \n",
       "3              VISam                    0                      0   \n",
       "4              VISpm                    0                      0   \n",
       "\n",
       "  rsa_mean_mean_spectral_embedding rsa_mean_mean_PCA  \n",
       "0                                0                 0  \n",
       "1                                0                 0  \n",
       "2                                0                 0  \n",
       "3                                0                 0  \n",
       "4                                0                 0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_exps_df = pd.DataFrame(boc.get_experiment_containers(targeted_structures= targeted_structures,\n",
    "                                                     cre_lines= cre_lines, imaging_depths = depths))\n",
    "\n",
    "rsa_types = ['rsa_mean_mean_mahala','rsa_random_mean_mahala', 'rsa_mean_mean_spectral_embedding', 'rsa_mean_mean_PCA']\n",
    "for rsa_ in rsa_types:\n",
    "    all_exps_df[rsa_] = 0\n",
    "    all_exps_df[rsa_] = all_exps_df[rsa_].astype(object)\n",
    "\n",
    "\n",
    "all_exps_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_id = all_exps_df.loc[0,'id']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Run for all natural scene sessions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Full pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_all_data(exp_id, only_responsive = True, stimuli = ['natural_scenes', 'static_gratings', 'natural_movie_one']):\n",
    "    \"\"\"Gets all the data. We'll only use session B.\n",
    "    \n",
    "    Returns a matrix of trials x n_neurons, and another of frames x neurons.\n",
    "    \n",
    "    Eye position\n",
    "    \"\"\"\n",
    "    dfs = []\n",
    "\n",
    "    for stim in stimuli:\n",
    "        session = boc.get_ophys_experiments(experiment_container_ids=[exp_id], stimuli=[stim])\n",
    "        \n",
    "        session_id =[session[i]['id'] for i in range(len(session)) \n",
    "                         if session[i]['session_type']=='three_session_B'][0]\n",
    "        if session_id==[]: \n",
    "            # This stimuli does not exist.\n",
    "            print('No '+stim+' for this experiment: ' + str(exp_id))\n",
    "            continue\n",
    "            \n",
    "        data_set = boc.get_ophys_experiment_data(ophys_experiment_id=session_id)\n",
    "        analysis_path = os.path.join(drive_path, 'ophys_experiment_analysis')\n",
    "        analysis_file = os.path.join(analysis_path, str(session_id) + '_three_session_B_analysis.h5')\n",
    "        \n",
    "        if stim == 'natural_scenes':  \n",
    "            ns = NaturalScenes.from_analysis_file(data_set, analysis_file)\n",
    "            df = ns.mean_sweep_response\n",
    "            \n",
    "#             avg_locs, std_locs = get_mean_pupil(data_set, stim)\n",
    "#             df['mean_pupil_loc_x'] = avg_locs[:,0]\n",
    "#             df['mean_pupil_loc_y'] = avg_locs[:,1]\n",
    "#             df['pupil_loc_std_x'] = std_locs[:,0]\n",
    "#             df['pupil_loc_std_y'] = std_locs[:,1]\n",
    "            \n",
    "            df['frame'] = data_set.get_stimulus_table('natural_scenes').frame\n",
    "            df.columns = df.columns.astype(str)\n",
    "            df['type'] = stim\n",
    "\n",
    "            dfs.append(df)\n",
    "            \n",
    "            \n",
    "\n",
    "        elif stim == 'static_gratings':\n",
    "            sg = StaticGratings.from_analysis_file(data_set, analysis_file)\n",
    "            df = sg.mean_sweep_response\n",
    "            \n",
    "#             avg_locs, std_locs = get_mean_pupil(data_set, stim)\n",
    "#             df['mean_pupil_loc_x'] = avg_locs[:,0]\n",
    "#             df['mean_pupil_loc_y'] = avg_locs[:,1]\n",
    "#             df['pupil_loc_std_x'] = std_locs[:,0]\n",
    "#             df['pupil_loc_std_y'] = std_locs[:,1]\n",
    "\n",
    "            stim_table = data_set.get_stimulus_table('static_gratings')\n",
    "            df = pd.merge(df,stim_table,left_index=True, right_index=True)\n",
    "            df.columns = df.columns.astype(str)\n",
    "            df['type'] = stim\n",
    "            dfs.append(df)\n",
    "\n",
    "        elif stim =='natural_movie_one':\n",
    "            nm = NaturalMovie.from_analysis_file(data_set, analysis_file, 'natural_movie_one')\n",
    "            df = pd.DataFrame(bin_movie_response(nm))\n",
    "            \n",
    "#             avg_locs, std_locs = get_mean_pupil(data_set, stim)\n",
    "#             df['mean_pupil_loc_x'] = avg_locs[:,0]\n",
    "#             df['mean_pupil_loc_y'] = avg_locs[:,1]\n",
    "#             df['pupil_loc_std_x'] = std_locs[:,0]\n",
    "#             df['pupil_loc_std_y'] = std_locs[:,1]\n",
    "\n",
    "            stim_table = data_set.get_stimulus_table('natural_movie_one')\n",
    "            df = pd.merge(df,stim_table[['repeat','frame']],left_index=True, right_index=True)\n",
    "            df.columns = df.columns.astype(str)\n",
    "            df['type'] = stim\n",
    "\n",
    "            dfs.append(df)\n",
    "            \n",
    "            \n",
    "        else:\n",
    "            raise Exception('stimulus not found')\n",
    "\n",
    "\n",
    "        # drop unresponsive cells\n",
    "        \n",
    "            \n",
    "    response = pd.concat(dfs)\n",
    "    \n",
    "    return response, ns.numbercells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mean_pupil(data_set, stimuli):\n",
    "    stim_table = data_set.get_stimulus_table(stimuli)\n",
    "    avg_locs = []\n",
    "    std_locs = []\n",
    "    pup_loc = data_set.get_pupil_location()\n",
    "    if stimuli == 'natural_movie_one':\n",
    "        for b in range(150*10):\n",
    "            start = stim_table.loc[b*6,'start']\n",
    "            end = stim_table.loc[b*6+5,'end']\n",
    "            these_pup_locs = pup_loc[1][start:end]\n",
    "            avg_locs.append(np.nanmean(these_pup_locs, axis=0))\n",
    "            std_locs.append(np.nanstd(these_pup_locs, axis=0))\n",
    "    else:        \n",
    "        for s in range(len(stim_table)):\n",
    "        # these are frame presentation numbers\n",
    "            start = stim_table.loc[s,'start'].astype(int)\n",
    "            end = stim_table.loc[s,'end'].astype(int)\n",
    "\n",
    "            these_pup_locs = pup_loc[1][start:end]\n",
    "            avg_locs.append(np.nanmean(these_pup_locs, axis=0))\n",
    "            std_locs.append(np.nanstd(these_pup_locs, axis=0))\n",
    "    return np.array(avg_locs), np.array(std_locs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bin_movie_response(nm):\n",
    "    sw = nm.get_sweep_response()\n",
    "    # first let's build a matric of n_scans, n_images\n",
    "    trial_responses = []\n",
    "    for repeat in range(10):\n",
    "        resp = sw.iloc[repeat]\n",
    "        nneurons = resp.shape[0]\n",
    "        n_frames = resp[0].shape[0]\n",
    "\n",
    "        # we'll use 200 ms bins, a.k.a. 6 frames\n",
    "        bin_size = 6\n",
    "        this_response = np.zeros((n_frames//bin_size ,nneurons))\n",
    "        for n in range(nneurons):\n",
    "            this_response[:,n] = binned_statistic(np.arange(n_frames), resp[n], statistic='mean',\n",
    "                                     bins =n_frames//bin_size )[0]\n",
    "        trial_responses.append(this_response)   \n",
    "            \n",
    "    response = np.vstack(trial_responses)\n",
    "        \n",
    "    return response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_mean_responses(response, method = 'mean'):\n",
    "    \"\"\"method = 'mean' or 'random\"\"\"\n",
    "    gratings = response.groupby('type').get_group('static_gratings')\n",
    "    movies = response.groupby('type').get_group('natural_movie_one')\n",
    "    scenes = response.groupby('type').get_group('natural_scenes')\n",
    "\n",
    "\n",
    "    if method =='random':\n",
    "        grating_response = gratings.groupby(('orientation', 'phase','spatial_frequency')).apply(\n",
    "                                    lambda x : x.iloc[np.random.randint(0,len(x))])\n",
    "        movie_response = movies.groupby('repeat').apply(\n",
    "                                    lambda x : x.iloc[np.random.randint(0,len(x))])\n",
    "        scene_response = scenes.groupby('frame').apply(\n",
    "                                    lambda x : x.iloc[np.random.randint(0,len(x))])\n",
    "    elif method =='mean':\n",
    "        grating_response = gratings.groupby(('orientation', 'phase','spatial_frequency')).apply(\n",
    "                                    lambda x : x.mean())\n",
    "        movie_response = movies.groupby('repeat').apply(\n",
    "                                    lambda x : x.mean())\n",
    "        scene_response = scenes.groupby('frame').apply(\n",
    "                                    lambda x : x.mean())\n",
    "\n",
    "    mean_response = pd.concat([grating_response, movie_response, scene_response])\n",
    "    return mean_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_precision(all_responses):\n",
    "        #using sklearn for its nice approximate inverse methods\n",
    "    if response.shape[0] < response.shape[1]:\n",
    "        raise('Must have more stimuli responses than neurons')\n",
    "\n",
    "    emp_cov = EmpiricalCovariance()\n",
    "    emp_cov.fit(response)\n",
    "    precision = emp_cov.get_precision()\n",
    "    \n",
    "    return precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "Opening /data/dynamic-brain-workshop/brain_observatory_cache/ophys_experiment_analysis/546698458_three_session_B_analysis.h5 in read-only mode\n",
      "Opening /data/dynamic-brain-workshop/brain_observatory_cache/ophys_experiment_analysis/546698458_three_session_B_analysis.h5 in read-only mode\n",
      "Opening /data/dynamic-brain-workshop/brain_observatory_cache/ophys_experiment_analysis/546698458_three_session_B_analysis.h5 in read-only mode\n",
      "Opening /data/dynamic-brain-workshop/brain_observatory_cache/ophys_experiment_analysis/546698458_three_session_B_analysis.h5 in read-only mode\n",
      "Opening /data/dynamic-brain-workshop/brain_observatory_cache/ophys_experiment_analysis/546698458_three_session_B_analysis.h5 in read-only mode\n",
      "Opening /data/dynamic-brain-workshop/brain_observatory_cache/ophys_experiment_analysis/546698458_three_session_B_analysis.h5 in read-only mode\n",
      "Opening /data/dynamic-brain-workshop/brain_observatory_cache/ophys_experiment_analysis/546698458_three_session_B_analysis.h5 in read-only mode\n",
      "Opening /data/dynamic-brain-workshop/brain_observatory_cache/ophys_experiment_analysis/546698458_three_session_B_analysis.h5 in read-only mode\n",
      "2\n",
      "Opening /data/dynamic-brain-workshop/brain_observatory_cache/ophys_experiment_analysis/508596945_three_session_B_analysis.h5 in read-only mode\n",
      "Opening /data/dynamic-brain-workshop/brain_observatory_cache/ophys_experiment_analysis/508596945_three_session_B_analysis.h5 in read-only mode\n",
      "Opening /data/dynamic-brain-workshop/brain_observatory_cache/ophys_experiment_analysis/508596945_three_session_B_analysis.h5 in read-only mode\n",
      "Opening /data/dynamic-brain-workshop/brain_observatory_cache/ophys_experiment_analysis/508596945_three_session_B_analysis.h5 in read-only mode\n",
      "Opening /data/dynamic-brain-workshop/brain_observatory_cache/ophys_experiment_analysis/508596945_three_session_B_analysis.h5 in read-only mode\n",
      "Opening /data/dynamic-brain-workshop/brain_observatory_cache/ophys_experiment_analysis/508596945_three_session_B_analysis.h5 in read-only mode\n",
      "Opening /data/dynamic-brain-workshop/brain_observatory_cache/ophys_experiment_analysis/508596945_three_session_B_analysis.h5 in read-only mode\n",
      "Opening /data/dynamic-brain-workshop/brain_observatory_cache/ophys_experiment_analysis/508596945_three_session_B_analysis.h5 in read-only mode\n",
      "3\n",
      "Opening /data/dynamic-brain-workshop/brain_observatory_cache/ophys_experiment_analysis/570889097_three_session_B_analysis.h5 in read-only mode\n",
      "Opening /data/dynamic-brain-workshop/brain_observatory_cache/ophys_experiment_analysis/570889097_three_session_B_analysis.h5 in read-only mode\n",
      "Opening /data/dynamic-brain-workshop/brain_observatory_cache/ophys_experiment_analysis/570889097_three_session_B_analysis.h5 in read-only mode\n",
      "Opening /data/dynamic-brain-workshop/brain_observatory_cache/ophys_experiment_analysis/570889097_three_session_B_analysis.h5 in read-only mode\n",
      "Opening /data/dynamic-brain-workshop/brain_observatory_cache/ophys_experiment_analysis/570889097_three_session_B_analysis.h5 in read-only mode\n",
      "Opening /data/dynamic-brain-workshop/brain_observatory_cache/ophys_experiment_analysis/570889097_three_session_B_analysis.h5 in read-only mode\n",
      "Opening /data/dynamic-brain-workshop/brain_observatory_cache/ophys_experiment_analysis/570889097_three_session_B_analysis.h5 in read-only mode\n",
      "Opening /data/dynamic-brain-workshop/brain_observatory_cache/ophys_experiment_analysis/570889097_three_session_B_analysis.h5 in read-only mode\n",
      "4\n",
      "Opening /data/dynamic-brain-workshop/brain_observatory_cache/ophys_experiment_analysis/510706209_three_session_B_analysis.h5 in read-only mode\n",
      "Opening /data/dynamic-brain-workshop/brain_observatory_cache/ophys_experiment_analysis/510706209_three_session_B_analysis.h5 in read-only mode\n",
      "Opening /data/dynamic-brain-workshop/brain_observatory_cache/ophys_experiment_analysis/510706209_three_session_B_analysis.h5 in read-only mode\n",
      "Opening /data/dynamic-brain-workshop/brain_observatory_cache/ophys_experiment_analysis/510706209_three_session_B_analysis.h5 in read-only mode\n",
      "Opening /data/dynamic-brain-workshop/brain_observatory_cache/ophys_experiment_analysis/510706209_three_session_B_analysis.h5 in read-only mode\n",
      "Opening /data/dynamic-brain-workshop/brain_observatory_cache/ophys_experiment_analysis/510706209_three_session_B_analysis.h5 in read-only mode\n",
      "Opening /data/dynamic-brain-workshop/brain_observatory_cache/ophys_experiment_analysis/510706209_three_session_B_analysis.h5 in read-only mode\n",
      "Opening /data/dynamic-brain-workshop/brain_observatory_cache/ophys_experiment_analysis/510706209_three_session_B_analysis.h5 in read-only mode\n",
      "5\n",
      "Opening /data/dynamic-brain-workshop/brain_observatory_cache/ophys_experiment_analysis/531124922_three_session_B_analysis.h5 in read-only mode\n",
      "Opening /data/dynamic-brain-workshop/brain_observatory_cache/ophys_experiment_analysis/531124922_three_session_B_analysis.h5 in read-only mode\n",
      "Opening /data/dynamic-brain-workshop/brain_observatory_cache/ophys_experiment_analysis/531124922_three_session_B_analysis.h5 in read-only mode\n",
      "Opening /data/dynamic-brain-workshop/brain_observatory_cache/ophys_experiment_analysis/531124922_three_session_B_analysis.h5 in read-only mode\n",
      "Opening /data/dynamic-brain-workshop/brain_observatory_cache/ophys_experiment_analysis/531124922_three_session_B_analysis.h5 in read-only mode\n",
      "Opening /data/dynamic-brain-workshop/brain_observatory_cache/ophys_experiment_analysis/531124922_three_session_B_analysis.h5 in read-only mode\n",
      "Opening /data/dynamic-brain-workshop/brain_observatory_cache/ophys_experiment_analysis/531124922_three_session_B_analysis.h5 in read-only mode\n",
      "Opening /data/dynamic-brain-workshop/brain_observatory_cache/ophys_experiment_analysis/531124922_three_session_B_analysis.h5 in read-only mode\n",
      "6\n",
      "Opening /data/dynamic-brain-workshop/brain_observatory_cache/ophys_experiment_analysis/501559087_three_session_B_analysis.h5 in read-only mode\n",
      "Opening /data/dynamic-brain-workshop/brain_observatory_cache/ophys_experiment_analysis/501559087_three_session_B_analysis.h5 in read-only mode\n",
      "Opening /data/dynamic-brain-workshop/brain_observatory_cache/ophys_experiment_analysis/501559087_three_session_B_analysis.h5 in read-only mode\n",
      "Opening /data/dynamic-brain-workshop/brain_observatory_cache/ophys_experiment_analysis/501559087_three_session_B_analysis.h5 in read-only mode\n",
      "Opening /data/dynamic-brain-workshop/brain_observatory_cache/ophys_experiment_analysis/501559087_three_session_B_analysis.h5 in read-only mode\n",
      "Opening /data/dynamic-brain-workshop/brain_observatory_cache/ophys_experiment_analysis/501559087_three_session_B_analysis.h5 in read-only mode\n",
      "Opening /data/dynamic-brain-workshop/brain_observatory_cache/ophys_experiment_analysis/501559087_three_session_B_analysis.h5 in read-only mode\n",
      "Opening /data/dynamic-brain-workshop/brain_observatory_cache/ophys_experiment_analysis/501559087_three_session_B_analysis.h5 in read-only mode\n",
      "7\n",
      "Opening /data/dynamic-brain-workshop/brain_observatory_cache/ophys_experiment_analysis/501490610_three_session_B_analysis.h5 in read-only mode\n",
      "Opening /data/dynamic-brain-workshop/brain_observatory_cache/ophys_experiment_analysis/501490610_three_session_B_analysis.h5 in read-only mode\n",
      "Opening /data/dynamic-brain-workshop/brain_observatory_cache/ophys_experiment_analysis/501490610_three_session_B_analysis.h5 in read-only mode\n",
      "Opening /data/dynamic-brain-workshop/brain_observatory_cache/ophys_experiment_analysis/501490610_three_session_B_analysis.h5 in read-only mode\n",
      "Opening /data/dynamic-brain-workshop/brain_observatory_cache/ophys_experiment_analysis/501490610_three_session_B_analysis.h5 in read-only mode\n",
      "Opening /data/dynamic-brain-workshop/brain_observatory_cache/ophys_experiment_analysis/501490610_three_session_B_analysis.h5 in read-only mode\n",
      "Opening /data/dynamic-brain-workshop/brain_observatory_cache/ophys_experiment_analysis/501490610_three_session_B_analysis.h5 in read-only mode\n",
      "Opening /data/dynamic-brain-workshop/brain_observatory_cache/ophys_experiment_analysis/501490610_three_session_B_analysis.h5 in read-only mode\n",
      "8\n",
      "Opening /data/dynamic-brain-workshop/brain_observatory_cache/ophys_experiment_analysis/501889084_three_session_B_analysis.h5 in read-only mode\n",
      "Opening /data/dynamic-brain-workshop/brain_observatory_cache/ophys_experiment_analysis/501889084_three_session_B_analysis.h5 in read-only mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening /data/dynamic-brain-workshop/brain_observatory_cache/ophys_experiment_analysis/501889084_three_session_B_analysis.h5 in read-only mode\n",
      "Opening /data/dynamic-brain-workshop/brain_observatory_cache/ophys_experiment_analysis/501889084_three_session_B_analysis.h5 in read-only mode\n",
      "Opening /data/dynamic-brain-workshop/brain_observatory_cache/ophys_experiment_analysis/501889084_three_session_B_analysis.h5 in read-only mode\n",
      "Opening /data/dynamic-brain-workshop/brain_observatory_cache/ophys_experiment_analysis/501889084_three_session_B_analysis.h5 in read-only mode\n",
      "Opening /data/dynamic-brain-workshop/brain_observatory_cache/ophys_experiment_analysis/501889084_three_session_B_analysis.h5 in read-only mode\n",
      "Opening /data/dynamic-brain-workshop/brain_observatory_cache/ophys_experiment_analysis/501889084_three_session_B_analysis.h5 in read-only mode\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for i, r in all_exps_df.iterrows():\n",
    "    if i<1:continue\n",
    "    print i\n",
    "    exp_id = all_exps_df['id'][i]\n",
    "    response_df, numbercells = get_all_data(exp_id)\n",
    "    response = response_df.iloc[:,:numbercells].values\n",
    "    \n",
    "    mean_response = get_mean_responses(response_df, method = 'mean')\n",
    "    mean_response = mean_response.iloc[:,:numbercells].values\n",
    "    \n",
    "    precision = get_precision(response)\n",
    "\n",
    "    \n",
    "    ### Get RSAs\n",
    "\n",
    "   \n",
    "    rsa_mean_mean_mahala = get_representational_similarity_response(mean_response, corr = 'mahalanobis', \n",
    "                                                                    precision = precision)\n",
    "    all_exps_df.set_value(i,'rsa_mean_mean_mahala', rsa_mean_mean_mahala)\n",
    "\n",
    "    rsa_random_mean_mahala = get_representational_similarity_response(mean_response, corr = 'mahalanobis', \n",
    "                                                                    precision = precision)\n",
    "    all_exps_df.set_value(i,'rsa_random_mean_mahala', rsa_random_mean_mahala)\n",
    "    \n",
    "#     se = SpectralEmbedding(n_components=50, n_jobs = -1)\n",
    "#     se.fit(response)\n",
    "#     rsa_mean_mean_SE = get_representational_similarity_response(mean_response, corr = 'euclidean', \n",
    "#                                                                    prefit_embedder = se)\n",
    "#     all_exps_df.set_value(i,'rsa_mean_mean_spectral_embedding', rsa_mean_mean_SE)\n",
    "    \n",
    "    \n",
    "    pca = PCA(whiten = True, n_components=min(50,numbercells-1))\n",
    "    pca.fit(response)\n",
    "    rsa_mean_mean_PCA = get_representational_similarity_response(mean_response, corr = 'euclidean', \n",
    "                                                                    prefit_embedder = pca)\n",
    "    all_exps_df.set_value(i,'rsa_mean_mean_PCA', rsa_mean_mean_PCA)\n",
    "    \n",
    "    all_exps_df.to_hdf('exps_w_RSA.h5','all_exps_df')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_exps_df.to_hdf('exps_w_RSA.h5','all_exps_df')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, r in all_exps_df.iterrows():\n",
    "    print i\n",
    "    exp_id = all_exps_df['id'][i]\n",
    "    response_df, numbercells = get_all_data(exp_id)\n",
    "    response = response_df.iloc[:,:numbercells].values\n",
    "    \n",
    "    mean_response = get_mean_responses(response_df, method = 'mean')\n",
    "    mean_response = mean_response.iloc[:,:numbercells].values\n",
    "    \n",
    "\n",
    "    \n",
    "    ### Get RSAs\n",
    "\n",
    "\n",
    "    \n",
    "    se = SpectralEmbedding(n_components=min(50,numbercells-1), n_jobs = -1)\n",
    "    se.fit(response)\n",
    "    rsa_mean_mean_SE = get_representational_similarity_response(mean_response, corr = 'euclidean', \n",
    "                                                                   prefit_embedder = se)\n",
    "    all_exps_df.set_value(i,'rsa_mean_mean_spectral_embedding', rsa_mean_mean_SE)\n",
    "\n",
    "    \n",
    "    all_exps_df.to_hdf('exps_w_RSA.h5','all_exps_df')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numbercells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
